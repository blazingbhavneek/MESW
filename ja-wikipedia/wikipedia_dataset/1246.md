# 最適制御

最適制御（さいてきせいぎょ、英: optimal control）は、特定の時間区間における評価関数の値を最小化（あるいは最大化）するように制御入力を決定する、動的システムに対する制御手法のひとつである。
形式的には、制御対象である動的システムの動特性を記述する状態方程式を拘束条件のひとつとして持つ汎関数の最適化問題として定式化される。
しばしばこの問題には、各時刻における状態ベクトルや制御入力に対する制約条件が含まれる。
最適制御理論は変分法の拡張であり、制御工学のみでなく応用数学（特に数理最適化）や数理物理学とも強い関わりを持つ。

歴史
最大原理と動的計画法は、1950年代の半ば頃にほぼ同時かつ独立に開発された。その基礎となる考え方は非常に古く、それらは先史から深く結びついている。
最大原理は、変分法におけるワイエルシュトラスの強い極値に関する必要条件を一般化したものであり、ハミルトニアンを"疑似"ハミルトニアン (英: pseudo-Hamiltonian)に置き換えることで得られる。この原理はコンスタンティン・カラテオドリによって1935年には既に垣間見えており、1950年にはマグナス・ヘステネスによって、より精緻なものとなった。しかし、今日我々が知る形の最大原理はレフ・ポントリャーギンの洞察が基礎にある。彼は最初に最短時間問題に対しこの問題を定式化し、その後ウラジミール・ボルチャンスキー レバス・ガムクレリゼおよび レフ・ロゾノエルらによって 1955 年から 1959 年に一般的なケースへと拡張された。ここで用いられた「針状の変分 (英: needle variations)」による手法はエドワード・マクシェーンによって 1939 年には既に用いられていたが、ボルチャンスキーはこれに加えて最大原理が最適性の必要条件にすぎないことを示した。彼は最大原理を、ポントリャーギンと共同研究者によって書かれたその有名な書籍において現在の形式で与えた。この本では、四番目の著者であるイェ・エフ・ミシチェンコによって確率的な最適制御問題が解かれている。
その後の研究によって、理論の根本的な修正を行うことなくアプローチを一般化することが可能になった。ひとつはフランシス・クラークによって始められた「非平滑解析 (英: nonsmooth analysis)」によるものであり、これは彼によって導入された一般化勾配 (英: generalized gradient) または一般化微分 (英: generalized derivative) を用いることで微分可能性の条件を弱めることにフォーカスする。これにより、ポントリャーギンらによる結果で得られていた区分的な連続関数よりも広いクラス（特にルベーグ可測な関数）を制御入力に用いることが可能になった。その他の拡張の方向性としては、時間遅れをもつシステムや無限次元システムなどがある。
ボルチャンスキーは、離散時間システムに対する最大原理の「弱い」バージョンを（このために必要となる数学的手法を開発した後で）示した。今日において、この結果はカルーシュ・クーン・タッカー条件を用いることで容易に示すことが出来るが、適当な凸性の仮定のもとで「真の」最大原理である十分条件を得ることが出来る。

一般的な定式化
最適制御問題は、対象となる動的システムの状態方程式を拘束条件としてもつ汎関数の制約付き最小化問題として定式化される。
いま、システムの状態ベクトルと制御入力ベクトルを 
  
    
      
        
          x
        
        ,
        
          u
        
      
    
    {\displaystyle {\boldsymbol {x}},{\boldsymbol {u}}}
  
 と表記し、それらの時刻 
  
    
      
        t
      
    
    {\displaystyle t}
  
 における値を 
  
    
      
        
          x
        
        (
        t
        )
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle {\boldsymbol {x}}(t)\in \mathbb {R} ^{n}}
  
 および 
  
    
      
        
          u
        
        (
        t
        )
        ∈
        
          
            R
          
          
            m
          
        
      
    
    {\displaystyle {\boldsymbol {u}}(t)\in \mathbb {R} ^{m}}
  
 によって表わす。
このとき、ある時間区間 
  
    
      
        [
        
          t
          
            0
          
        
        ,
        
          t
          
            f
          
        
        ]
      
    
    {\displaystyle [t_{0},t_{f}]}
  
 における最適制御問題の一般形は次のように記述することが出来る。

決定変数: 
  
    
      
        {
        
          x
        
        (
        t
        )
        ∈
        
          
            R
          
          
            n
          
        
        ∣
        t
        ∈
        [
        
          t
          
            0
          
        
        ,
        
          t
          
            f
          
        
        ]
        }
        ,
        
        {
        
          u
        
        (
        t
        )
        ∈
        
          
            R
          
          
            m
          
        
        ∣
        t
        ∈
        [
        
          t
          
            0
          
        
        ,
        
          t
          
            f
          
        
        ]
        }
      
    
    {\displaystyle \{{\boldsymbol {x}}(t)\in \mathbb {R} ^{n}\mid t\in [t_{0},t_{f}]\},\quad \{{\boldsymbol {u}}(t)\in \mathbb {R} ^{m}\mid t\in [t_{0},t_{f}]\}}
  

目的関数:

制約条件:

式 (1-1) で定義される汎関数 
  
    
      
        J
      
    
    {\displaystyle J}
  
 において、関数 
  
    
      
        E
        ,
        F
      
    
    {\displaystyle E,F}
  
 はそれぞれ終端コスト (terminal cost) およびステージコスト (stage cost) と呼ばれる。
また、式(1-2) は対象となるシステムの状態方程式である。
式(1-3) は状態ベクトルに関する終端拘束条件 (terminal constraint) であり、式 (1-4) および (1-5) は各時刻における状態ベクトルおよび制御入力に課せられる制約条件を意味する。
上のように記述される最適制御問題は、特にボルザ問題 (Bolza problem) と呼ばれる。
特別な場合として、第一項すなわち 
  
    
      
        E
      
    
    {\displaystyle E}
  
 が恒等的にゼロであるような場合をラグランジュ問題 (Lagrange problem)、第二項すなわち 
  
    
      
        F
      
    
    {\displaystyle F}
  
 が恒等的にゼロである場合をメイヤー問題 (Mayer problem) と言う。

一般的な解法
一般的な最適制御問題の解法は、レフ・ポントリャーギンとその共同研究者による最大原理と、リチャード・E・ベルマンによる動的計画法によるアプローチに大別される。
説明のため、本節では初期・終端時刻 
  
    
      
        
          t
          
            0
          
        
        ,
        
          t
          
            f
          
        
      
    
    {\displaystyle t_{0},t_{f}}
  
 が固定された次のような最適制御問題を対象とする。

  
    
      
        
          
            
              
                
                  minimize
                
                
              
              
                J
                [
                
                  x
                
                ,
                
                  u
                
                ]
                =
                E
                (
                
                  x
                
                (
                
                  t
                  
                    f
                  
                
                )
                )
                +
                
                  ∫
                  
                    
                      t
                      
                        0
                      
                    
                  
                  
                    
                      t
                      
                        f
                      
                    
                  
                
                F
                (
                
                  x
                
                (
                t
                )
                ,
                
                  u
                
                (
                t
                )
                ,
                t
                )
                
                
                  d
                
                t
              
            
            
              
                
                  subject to
                
                
              
              
                
                  
                    
                      x
                      ˙
                    
                  
                
                (
                t
                )
                =
                
                  f
                
                (
                
                  x
                
                (
                t
                )
                ,
                
                  u
                
                (
                t
                )
                ,
                t
                )
                ,
                
                
                  u
                
                (
                t
                )
                ∈
                
                  
                    U
                  
                
                ,
                
                ∀
                t
                ∈
                [
                
                  t
                  
                    0
                  
                
                ,
                
                  t
                  
                    f
                  
                
                ]
              
            
            
              
              
                
                  x
                
                (
                
                  t
                  
                    0
                  
                
                )
                =
                
                  
                    x
                  
                  
                    0
                  
                
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\text{minimize}}\quad &J[{\boldsymbol {x}},{\boldsymbol {u}}]=E({\boldsymbol {x}}(t_{f}))+\int _{t_{0}}^{t_{f}}F({\boldsymbol {x}}(t),{\boldsymbol {u}}(t),t)\,\mathrm {d} t\\{\text{subject to}}\quad &{\dot {\boldsymbol {x}}}(t)={\boldsymbol {f}}({\boldsymbol {x}}(t),{\boldsymbol {u}}(t),t),\quad {\boldsymbol {u}}(t)\in {\mathcal {U}},\quad \forall t\in [t_{0},t_{f}]\\&{\boldsymbol {x}}(t_{0})={\boldsymbol {x}}_{0}\end{aligned}}}

動的計画法
動的計画法による解法では、最適制御問題をハミルトン・ヤコビ・ベルマン方程式と呼ばれる偏微分方程式へと帰着させる。
いま、上の最適制御問題に対し次のような関数を定義する（
  
    
      
        
          min
          
            
              u
            
            [
            
              t
              
                ,
              
            
            
              t
              
                f
              
            
            ]
          
        
        I
        (
        
          u
        
        )
      
    
    {\textstyle \min _{{\boldsymbol {u}}[t_{,}t_{f}]}I({\boldsymbol {u}})}
  
 は汎関数 
  
    
      
        I
      
    
    {\displaystyle I}
  
 を区間 
  
    
      
        [
        t
        ,
        
          t
          
            f
          
        
        ]
      
    
    {\displaystyle [t,t_{f}]}
  
 における 
  
    
      
        
          u
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {u}}(t)}
  
 の値について最小化することを意味する）:

  
    
      
        V
        (
        
          x
        
        ,
        t
        )
        =
        
          min
          
            
              u
            
            [
            t
            ,
            
              t
              
                f
              
            
            ]
          
        
        
          
            {
          
        
        E
        (
        
          x
        
        (
        
          t
          
            f
          
        
        )
        )
        +
        
          ∫
          
            t
          
          
            
              t
              
                f
              
            
          
        
        F
        (
        
          x
        
        (
        t
        )
        ,
        
          u
        
        (
        t
        )
        ,
        t
        )
        
        
          d
        
        t
        
          
            }
          
        
        
          
            
              |
            
          
          
            
              x
            
            (
            t
            )
            =
            
              x
            
          
        
      
    
    {\displaystyle V({\boldsymbol {x}},t)=\min _{{\boldsymbol {u}}[t,t_{f}]}{\bigg \{}E({\boldsymbol {x}}(t_{f}))+\int _{t}^{t_{f}}F({\boldsymbol {x}}(t),{\boldsymbol {u}}(t),t)\,\mathrm {d} t{\bigg \}}{\bigg |}_{{\boldsymbol {x}}(t)={\boldsymbol {x}}}}
  

この関数は初期時刻 
  
    
      
        t
      
    
    {\displaystyle t}
  
 における状態が 
  
    
      
        
          x
        
      
    
    {\displaystyle {\boldsymbol {x}}}
  
 であった場合における目的関数の最小値を意味しており、価値関数 (value function) と呼ばれる。
目的関数の定義より、
  
    
      
        V
        (
        
          
            x
          
          
            0
          
        
        ,
        0
        )
      
    
    {\displaystyle V({\boldsymbol {x}}_{0},0)}
  
 は元々の最適制御問題における目的関数の最小値に対応する。
また、終端時刻 
  
    
      
        
          t
          
            f
          
        
      
    
    {\displaystyle t_{f}}
  
 における価値関数は次式を満たす。

さらに、上のように定義された価値関数 
  
    
      
        V
      
    
    {\displaystyle V}
  
 は次のハミルトン・ヤコビ・ベルマン方程式を満たす。

ここで関数 
  
    
      
        H
      
    
    {\displaystyle H}
  
 は ハミルトニアン (Hamiltonian) と呼ばれ、次のように定義される。

すなわち、偏微分方程式 (2-2) と終端時刻 
  
    
      
        
          t
          
            f
          
        
      
    
    {\displaystyle t_{f}}
  
 における境界条件 (2-1) を満たす価値関数 
  
    
      
        V
        (
        
          x
        
        ,
        t
        )
      
    
    {\displaystyle V({\boldsymbol {x}},t)}
  
 を求めることが出来れば、各時刻における最適な制御入力は次のように求められる。

  
    
      
        
          
            u
          
          
            ∗
          
        
        (
        t
        )
        =
        arg
        ⁡
        
          min
          
            
              u
            
            ∈
            
              
                U
              
            
          
        
        H
        
          
            (
          
        
        
          x
        
        (
        t
        )
        ,
        
          
            
              ∂
              V
            
            
              ∂
              
                x
              
            
          
        
        (
        
          x
        
        (
        t
        )
        ,
        t
        )
        ,
        
          u
        
        ,
        t
        
          
            )
          
        
      
    
    {\displaystyle {\boldsymbol {u}}^{*}(t)=\arg \min _{{\boldsymbol {u}}\in {\mathcal {U}}}H{\bigg (}{\boldsymbol {x}}(t),{\frac {\partial V}{\partial {\boldsymbol {x}}}}({\boldsymbol {x}}(t),t),{\boldsymbol {u}},t{\bigg )}}

最大原理
最大原理は、変分法を適用することで得られる最適性の必要条件である。
いま、
  
    
      
        
          
            u
          
          
            ∗
          
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {u}}^{*}(t)}
  
 を最適な制御入力とし、そのときの状態ベクトルを 
  
    
      
        
          
            x
          
          
            ∗
          
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {x}}^{*}(t)}
  
 と表記する。
このとき、これらの変数は時間区間 
  
    
      
        [
        
          t
          
            0
          
        
        ,
        
          t
          
            f
          
        
        ]
      
    
    {\displaystyle [t_{0},t_{f}]}
  
 において次に与えられる関係式をすべて満たす。

  
    
      
        
          
            
              
                x
                ˙
              
            
          
          
            ∗
          
        
        (
        t
        )
        =
        
          
            
              ∂
              H
            
            
              ∂
              
                p
              
            
          
        
        (
        
          
            x
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            p
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            u
          
          
            ∗
          
        
        (
        t
        )
        ,
        t
        )
        ,
        
        
          
            x
          
          
            ∗
          
        
        (
        
          t
          
            0
          
        
        )
        =
        
          
            x
          
          
            0
          
        
      
    
    {\displaystyle {\dot {\boldsymbol {x}}}^{*}(t)={\frac {\partial H}{\partial {\boldsymbol {p}}}}({\boldsymbol {x}}^{*}(t),{\boldsymbol {p}}^{*}(t),{\boldsymbol {u}}^{*}(t),t),\quad {\boldsymbol {x}}^{*}(t_{0})={\boldsymbol {x}}_{0}}
  

  
    
      
        
          
            
              
                p
                ˙
              
            
          
          
            ∗
          
        
        (
        t
        )
        =
        −
        
          
            
              ∂
              H
            
            
              ∂
              
                x
              
            
          
        
        (
        
          
            x
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            p
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            u
          
          
            ∗
          
        
        (
        t
        )
        ,
        t
        )
        ,
        
        
          
            p
          
          
            ∗
          
        
        (
        
          t
          
            f
          
        
        )
        =
        
          
            
              ∂
              E
            
            
              ∂
              
                x
              
            
          
        
        (
        
          
            x
          
          
            ∗
          
        
        (
        
          t
          
            f
          
        
        )
        ,
        t
        )
      
    
    {\displaystyle {\dot {\boldsymbol {p}}}^{*}(t)=-{\frac {\partial H}{\partial {\boldsymbol {x}}}}({\boldsymbol {x}}^{*}(t),{\boldsymbol {p}}^{*}(t),{\boldsymbol {u}}^{*}(t),t),\quad {\boldsymbol {p}}^{*}(t_{f})={\frac {\partial E}{\partial {\boldsymbol {x}}}}({\boldsymbol {x}}^{*}(t_{f}),t)}
  

  
    
      
        H
        (
        
          
            x
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            p
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            u
          
          
            ∗
          
        
        (
        t
        )
        ,
        t
        )
        ≤
        H
        (
        
          
            x
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            p
          
          
            ∗
          
        
        (
        t
        )
        ,
        
          
            u
          
          ′
        
        ,
        t
        )
        ,
        
        ∀
        
          
            u
          
          ′
        
        ∈
        
          
            U
          
        
      
    
    {\displaystyle H({\boldsymbol {x}}^{*}(t),{\boldsymbol {p}}^{*}(t),{\boldsymbol {u}}^{*}(t),t)\leq H({\boldsymbol {x}}^{*}(t),{\boldsymbol {p}}^{*}(t),{\boldsymbol {u}}',t),\quad \forall {\boldsymbol {u}}'\in {\mathcal {U}}}
  

ここで関数 
  
    
      
        H
      
    
    {\displaystyle H}
  
 は式 (2-3) で定義されたハミルトニアンである。
また、変数 
  
    
      
        
          p
        
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle {\boldsymbol {p}}\in \mathbb {R} ^{n}}
  
 は随伴変数 (adjacent variable) や共状態 (costate) と呼ばれる。
随伴変数は、状態方程式を最適化問題の等式制約とみなした場合におけるラグランジュ乗数に対応する。

最大原理と動的計画法の比較
ポントリャーギンの最大原理は最適性の必要条件であり、その解は時間の関数、すなわち開ループ制御となる。
一方、動的計画法は最適性の十分条件を与え、最適な制御入力はシステムの状態の関数、すなわち閉ループ制御として記述される。
動的計画法では、任意の状態に対する制御入力を得るためにハミルトン-ヤコビ-ベルマン方程式を解く必要がある。これは偏微分方程式であるため、解析的に解くことは一般的に不可能である。数値的に解く場合であっても、偏微分方程式の解を保持するために必要となる計算量は状態の次元に対し指数的に増大する。動的計画法におけるこのような問題は一般に次元の呪いとして知られている。
一方、最大原理では解くべき問題は常微分方程式として与えられるため、HJB 方程式と比べて解を求めるのは容易である。
動的計画法は、システムが確定的・確率的な場合いずれにおいても適用することができる。
一方、最大原理は（特殊な場合を除き）確率システムには適用できない。

LQ 制御問題
解析的に求められる最適制御問題の例として、線形二次制御 (linear-quadratic control; LQ control) が広く知られている。
LQ 制御問題では、次のような線形システムを制御対象とする:

  
    
      
        
          
            
              x
              ˙
            
          
        
        (
        t
        )
        =
        
          A
        
        (
        t
        )
        
          x
        
        (
        t
        )
        +
        
          B
        
        (
        t
        )
        
          u
        
        (
        t
        )
      
    
    {\displaystyle {\dot {\boldsymbol {x}}}(t)={\boldsymbol {A}}(t){\boldsymbol {x}}(t)+{\boldsymbol {B}}(t){\boldsymbol {u}}(t)}
  

また、目的関数は状態ベクトルと制御入力に関する二次形式として与えられる:

  
    
      
        J
        [
        
          x
        
        ,
        
          u
        
        ]
        =
        
          
            1
            2
          
        
        
          
            x
          
          
            
              T
            
          
        
        (
        
          t
          
            f
          
        
        )
        
          
            S
          
          
            f
          
        
        
          x
        
        (
        
          t
          
            f
          
        
        )
        +
        
          
            1
            2
          
        
        
          ∫
          
            
              t
              
                0
              
            
          
          
            
              t
              
                f
              
            
          
        
        
          
            [
          
        
        
          
            x
          
          
            
              T
            
          
        
        (
        t
        )
        
          Q
        
        (
        t
        )
        
          x
        
        (
        t
        )
        +
        
          
            u
          
          
            
              T
            
          
        
        (
        t
        )
        
          R
        
        (
        t
        )
        
          u
        
        (
        t
        )
        
          
            ]
          
        
        
          d
        
        t
      
    
    {\displaystyle J[{\boldsymbol {x}},{\boldsymbol {u}}]={\frac {1}{2}}{\boldsymbol {x}}^{\mathsf {T}}(t_{f}){\boldsymbol {S}}_{f}{\boldsymbol {x}}(t_{f})+{\frac {1}{2}}\int _{t_{0}}^{t_{f}}{\bigg [}{\boldsymbol {x}}^{\mathsf {T}}(t){\boldsymbol {Q}}(t){\boldsymbol {x}}(t)+{\boldsymbol {u}}^{\mathsf {T}}(t){\boldsymbol {R}}(t){\boldsymbol {u}}(t){\bigg ]}\mathrm {d} t}
  

ただし、
  
    
      
        
          Q
        
        (
        t
        )
        ,
        
          
            S
          
          
            f
          
        
        ∈
        
          
            R
          
          
            n
            ×
            n
          
        
      
    
    {\displaystyle {\boldsymbol {Q}}(t),{\boldsymbol {S}}_{f}\in \mathbb {R} ^{n\times n}}
  
 および 
  
    
      
        
          R
        
        (
        t
        )
        ∈
        
          
            R
          
          
            m
            ×
            m
          
        
      
    
    {\displaystyle {\boldsymbol {R}}(t)\in \mathbb {R} ^{m\times m}}
  
 は対称行列であり、一般に（準）正定値行列として与えられる（
  
    
      
        
          R
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {R}}(t)}
  
 は正則である必要があるため、一般には正定値行列と仮定される）。
この最適制御問題における最適な制御入力は、次のように与えられる。

  
    
      
        
          u
        
        (
        t
        )
        =
        −
        
          
            R
          
          
            −
            1
          
        
        (
        t
        )
        
          
            B
          
          
            
              T
            
          
        
        (
        t
        )
        
          S
        
        (
        t
        )
        
          x
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {u}}(t)=-{\boldsymbol {R}}^{-1}(t){\boldsymbol {B}}^{\mathsf {T}}(t){\boldsymbol {S}}(t){\boldsymbol {x}}(t)}
  

ただし、
  
    
      
        
          S
        
        (
        t
        )
        ∈
        
          
            R
          
          
            n
            ×
            n
          
        
      
    
    {\displaystyle {\boldsymbol {S}}(t)\in \mathbb {R} ^{n\times n}}
  
 は次の行列微分方程式の解として与えられる対称行列である。

  
    
      
        
          
            
              S
              ˙
            
          
        
        (
        t
        )
        +
        
          S
        
        (
        t
        )
        
          A
        
        (
        t
        )
        +
        
          
            A
          
          
            
              T
            
          
        
        
          S
        
        (
        t
        )
        −
        
          S
        
        (
        t
        )
        
          B
        
        (
        t
        )
        
          
            R
          
          
            −
            1
          
        
        (
        t
        )
        
          
            B
          
          
            
              T
            
          
        
        
          S
        
        (
        t
        )
        +
        
          Q
        
        (
        t
        )
        =
        
          0
        
        ,
        
        
          S
        
        (
        
          t
          
            f
          
        
        )
        =
        
          
            S
          
          
            f
          
        
      
    
    {\displaystyle {\dot {\boldsymbol {S}}}(t)+{\boldsymbol {S}}(t){\boldsymbol {A}}(t)+{\boldsymbol {A}}^{\mathsf {T}}{\boldsymbol {S}}(t)-{\boldsymbol {S}}(t){\boldsymbol {B}}(t){\boldsymbol {R}}^{-1}(t){\boldsymbol {B}}^{\mathsf {T}}{\boldsymbol {S}}(t)+{\boldsymbol {Q}}(t)={\boldsymbol {0}},\quad {\boldsymbol {S}}(t_{f})={\boldsymbol {S}}_{f}}
  

上の微分方程式はリッカチ微分方程式 (Riccati differential equation) と呼ばれ、終端時刻 
  
    
      
        
          t
          
            f
          
        
      
    
    {\displaystyle t_{f}}
  
 から始めて逆向きに進むことで数値的に解くことが出来る。
上のように設計される制御器は、特に（有限時間区間における）線形二次レギュレータ（linear-quadratic regulator; LQR）または 最適レギュレータ（optimal regulator）と呼ばれている。
無限時間区間における最適レギュレータ問題についても、同様に議論することが出来る:

状態方程式:

  
    
      
        
          
            
              x
              ˙
            
          
        
        (
        t
        )
        =
        
          A
        
        
          x
        
        (
        t
        )
        +
        
          B
        
        
          u
        
        (
        t
        )
        ,
        
        
          x
        
        (
        0
        )
        =
        
          
            x
          
          
            0
          
        
      
    
    {\displaystyle {\dot {\boldsymbol {x}}}(t)={\boldsymbol {A}}{\boldsymbol {x}}(t)+{\boldsymbol {B}}{\boldsymbol {u}}(t),\quad {\boldsymbol {x}}(0)={\boldsymbol {x}}_{0}}
  

目的関数:

  
    
      
        J
        =
        
          
            1
            2
          
        
        
          ∫
          
            0
          
          
            ∞
          
        
        
          
            [
          
        
        
          
            x
          
          
            
              T
            
          
        
        (
        t
        )
        
          Q
        
        
          x
        
        (
        t
        )
        +
        
          
            u
          
          
            
              T
            
          
        
        (
        t
        )
        
          R
        
        
          u
        
        (
        t
        )
        
          
            ]
          
        
        
          d
        
        t
      
    
    {\displaystyle J={\frac {1}{2}}\int _{0}^{\infty }{\big [}{\boldsymbol {x}}^{\mathsf {T}}(t){\boldsymbol {Q}}{\boldsymbol {x}}(t)+{\boldsymbol {u}}^{\mathsf {T}}(t){\boldsymbol {R}}{\boldsymbol {u}}(t){\big ]}\mathrm {d} t}
  

ただし、定数行列 
  
    
      
        
          Q
        
        ∈
        
          
            R
          
          
            n
            ×
            n
          
        
      
    
    {\displaystyle {\boldsymbol {Q}}\in \mathbb {R} ^{n\times n}}
  
 と 
  
    
      
        
          R
        
        ∈
        
          
            R
          
          
            m
            ×
            m
          
        
      
    
    {\displaystyle {\boldsymbol {R}}\in \mathbb {R} ^{m\times m}}
  
 はそれぞれ準正定値、正定値行列であり、
  
    
      
        (
        
          A
        
        ,
        
          B
        
        )
      
    
    {\displaystyle ({\boldsymbol {A}},{\boldsymbol {B}})}
  
 は可制御であると仮定する。
このとき、最適な制御入力は次のように記述される。

  
    
      
        
          u
        
        (
        t
        )
        =
        −
        
          
            R
          
          
            −
            1
          
        
        
          
            B
          
          
            
              T
            
          
        
        
          S
        
        
          x
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {u}}(t)=-{\boldsymbol {R}}^{-1}{\boldsymbol {B}}^{\mathsf {T}}{\boldsymbol {S}}{\boldsymbol {x}}(t)}
  

ただし、
  
    
      
        
          S
        
        ∈
        
          
            R
          
          
            n
            ×
            n
          
        
      
    
    {\displaystyle {\boldsymbol {S}}\in \mathbb {R} ^{n\times n}}
  
 は次のリッカチ代数方程式 (algebraic Riccati equation) を満たす唯一の正定値行列である。

  
    
      
        
          S
        
        
          A
        
        +
        
          
            A
          
          
            
              T
            
          
        
        
          S
        
        −
        
          S
        
        
          B
        
        
          
            R
          
          
            −
            1
          
        
        
          
            B
          
          
            
              T
            
          
        
        
          S
        
        +
        
          Q
        
        =
        
          0
        
      
    
    {\displaystyle {\boldsymbol {S}}{\boldsymbol {A}}+{\boldsymbol {A}}^{\mathsf {T}}{\boldsymbol {S}}-{\boldsymbol {S}}{\boldsymbol {B}}{\boldsymbol {R}}^{-1}{\boldsymbol {B}}^{\mathsf {T}}{\boldsymbol {S}}+{\boldsymbol {Q}}={\boldsymbol {0}}}
  

上の最適制御入力を用いたときの閉ループ系

  
    
      
        
          x
        
        (
        t
        )
        =
        (
        
          A
        
        −
        
          B
        
        
          
            R
          
          
            −
            1
          
        
        
          
            B
          
          
            
              T
            
          
        
        
          S
        
        )
        
          x
        
        (
        t
        )
      
    
    {\displaystyle {\boldsymbol {x}}(t)=({\boldsymbol {A}}-{\boldsymbol {B}}{\boldsymbol {R}}^{-1}{\boldsymbol {B}}^{\mathsf {T}}{\boldsymbol {S}}){\boldsymbol {x}}(t)}
  

における原点は漸近安定な平衡点となることが知られている。

数値解法
一般的な最適制御問題は非線形であり、LQ 制御問題のような解析解をもつとは限らない。
そのため、数値計算を用いて最適制御問題を解くアプローチが必要となる。

間接法
最適制御理論の初期（およそ1950年代から1980年代まで）に好まれたアプローチは間接法（英: indirect method）である。
間接法では、変分法によって得られる一次の最適性条件を満たすような制御入力（および最適軌道）を求める。
この条件は二点（複雑な問題の場合はさらに多くの）境界値問題で与えられ、ハミルトニアンの微分を含むことに起因する特殊な構造をもつ。
この境界値問題は、適切な境界条件あるいは横断性条件（英: transversality condition）の下で解かれる。
間接法を使う利点は、境界値問題を解くことで得られる状態と随伴変数が最適性の必要条件を満たす極値軌道（英: extremal trajectory）を取ることが保証されることである。
欠点は、元の最適制御問題の複雑さによっては（時間区間が長い場合、内点の制約条件のある場合など）境界値問題を解くことが極端に難しくなることである。
間接法を実装したソフトウェアとして有名なものは BNDSCO である。

直接法
1980年代以降において、数値最適制御で注目を集めているアプローチは直接法（英: direct method）と呼ばれる。
これらの手法は、連続関数である制御入力や状態・随伴変数の軌道を（多項式近似や区分線形近似などを用いて）有限次元ベクトル空間の点として近似し、汎関数最小化問題を（有限次元の）非線形計画問題 (nonlinear programming; NLP) へと帰着させることで最適解を求める。
採用する直接法の種類によって、解くべき NLP の規模は大きく左右される。
直接シューティング法（英: direct shooting method）や準線形化法（英: quasilinearization method）などでは、問題の規模は極めて小さいものとなり、擬スペクトル最適制御では中規模となる。
直接選点法（英: direct collocation method）では大規模な問題となり、結果として得られる NLP は文字通り数千・数万規模の決定変数や制約条件を持つ可能性がある。
境界値問題を解くことよりも直接法から導出される大規模な NLP を解くことの方が簡単であるということは直感に反するが、多くの場合において事実である。
特に直接選点法において計算が相対的に容易となる理由は、導出された NLP がスパース性を持ち、そのような性質を持つ大規模な NLP を効率的に解く最適化ソフトウェアが数多く存在するためである。
スパース性を生かした NLP ソルバーとして、例えば SNOPT が良く知られている。
その結果として、直接法（特に近年において非常に人気のある直接選点法）によって解くことが出来る問題の範囲は、間接法と比較して非常に大きくなる。
今日における直接法の人気は非常に高まっており、これらの手法を採用した精巧なソフトウェアが数多く開発されている。
良く知られているものとして、DIRCOL、SOCS、OTIS、GESOP/ASTOS、DITAN、PyGMO/PyKEP などが挙げられる。
また、近年におけるMATLABプログラミング言語の台頭に伴い、MATLAB上で使用可能な最適制御ソフトウェアがより一般的なものとなっている。
直接法を実装した学術的に開発された MATLAB ツールの例として、RIOTS、DIDO、DIRECT、FALCON.m、GPOPS などがある。
産業界で開発されたツールとしては PROPT などがある。
これらのソフトウェアは、学術研究と産業問題の両面において人々が複雑な最適制御問題を探求する機会を著しく増大させた。
結果として、複雑な最適制御問題におけるコーディングが TOMLAB などの汎用の MATLAB 最適化環境によって（以前から使用可能であった）C言語やFORTRANのものと比較して著しく簡単に出来るようになったことは注目に値する。

出典
関連項目
数理最適化
動的計画法
ハミルトン-ヤコビ-ベルマン方程式
変分法
最速降下曲線
カルマンフィルター
H∞制御理論
モデル予測制御
# フィルタリング (有害サイトアクセス制限)

フィルタリング（英: filtering）とは、インターネット上のウェブページなどを一定の基準で評価判別し、選択的に排除する機能のこと。
ここでは、主にカタカナ語としての「フィルタリング」において意味される、青少年保護を目的として政府、インターネットプロバイダ（接続業者）、親権者、コンピュータ管理者などが行うものについて述べる。この種の技術全般についてはコンテンツフィルタリング、ネット検閲を参照。
親権者等による、DVDなども含めたメディアの選択的な排除は「ペアレンタルコントロール」と呼ばれる。またアクセス排除ではなく、内容レベルの可視化を目的とした概念にレイティングがある。

概要
フィルタリングは、様々な価値観に基づき発信されるウェブページなどを、PC向けのソフトウェアや、インターネットサービスプロバイダーや携帯電話事業者によって運用されるプログラムによって評価判別し、情報の配信を許可あるいは遮断する機能である。主に特定のサイトの閲覧を不可とするよう指定する「ブラックリスト方式」と、閲覧したいサイトやカテゴリーを指定する「ホワイトリスト方式」がある。

携帯電話フィルタリングの登場と課題
政府による取り組み
近年は携帯電話（フィーチャーフォン・スマートフォン）の普及により、インターネット閲覧機能の充実と通信料金の低料金化が進行し、携帯電話の低年齢層への普及と共に、保護者の目の届かない状況で青少年がインターネット上の情報に触れる機会が拡大した。
2005年からスウェーデンがインターネットの児童ポルノのブロッキングを開始した。(しかし、児童ポルノのブロッキング以降もスウェーデンでは強姦犯罪の増加が止まなかった。)
2005年6月に、政府のIT安心会議（インターネット上における違法・有害情報等に関する関係省庁連絡会議）では，フィルタリングソフトの普及，プロバイダ等による自主規制の支援等を柱とする「インターネット上における違法・有害情報対策について」を策定し、それに基づき政府一体となって、インターネットのフィルタリングの普及を促進した。
2006年4月以降、警察庁の「バーチャル社会のもたらす弊害から子どもを守る研究会」では、ゲームやインターネット、携帯電話など情報化の進展が子どもたちにもたらす弊害について審議し、中でも重要性・緊急性の高い携帯電話に関する課題について2006年9月22日に、報告書にとりまとめた。
そして、インターネットへのアクセスを通じ青少年が被害を受けた犯罪が広く報道され、青少年保護の観点からの問題の指摘が相次いだ。
2007年12月10日に、総務省から、携帯電話事業者などに対して、フィルタリングの導入促進のため、青少年のフィルタリング使用の原則化と不使用についての親権者の意思確認実施を促す総務大臣要請が行われ、携帯電話事業者各社からも同日付で大臣要請を実施する取り組み内容が発表されるに至った。
しかしながら、このことを契機として携帯電話フィルタリングの抱える問題が顕在化することとなった。すなわち、現行の携帯電話フィルタリングは過度に画一的で選択性がなく、基準選定の透明性や公正性が確保されていなかった。このことが青少年におけるフィルタリングの普及を妨げているという問題である。具体的には以下のような点などが挙げられている。

携帯電話フィルタリングの種類は、基本的に携帯電話事業者が提供する「ブラックリスト方式」と「ホワイトリスト方式」の2つしかなく、カスタマイズ性がない
前者の「ブラックリスト方式」においては、携帯電話フィルタリングで制限される範囲が、ウェブサイトの健全性の有無とは無関係にサイト分野を類型化したカテゴリー単位となっているなど、制限される範囲が過度に広範であること
青少年に無害とされるべきはずの、特定の政党（野党）や著名な神社仏閣のウェブサイトを含むカテゴリーが制限対象となっているなど、カテゴリーの選定基準自体が不透明であること
また後者の「ホワイトリスト方式」において、その選定の要件となる公式サイトの認定に当たって、サイトの健全性とは別の要素である携帯事業者のビジネス性等を考慮した総合的な判断により拒否されることがあり、サイト事業者とビジネスで競合する面のある携帯電話事業者の恣意性が指摘されていること
同性愛もフィルタリングの対象になっているが、これが同性愛者差別へ繋がる恐れがあるという意見があること
2009年3月に、児童ポルノ流通防止協議会が、警察庁の検討会の総合セキュリティ対策会議の報告書において、インターネット利用者によるフィルタリングの活用や、あるいはプロバイダー側でブロッキングする等で児童ポルノの流通を防止する施策を提案した。

携帯電話フィルタリングの改善策と今後
2009年4月25日、このような問題に対する現行モデルの改善策が、総務省が開催する「インターネット上の違法・有害情報への対応に関する検討会」の中間とりまとめで提示され、同日付の総務省要請として携帯電話事業者各社になされた（後述）。これを受けた携帯電話事業者各社は、2008年夏以降を予定していた既存の青少年契約者に対するフィルタリング使用の原則化を延期。9月12日に携帯電話事業者5社と電気通信事業者協会が正式な発表を行い、ブラックリスト方式において、モバイルコンテンツ審査・運用監視機構の認定サイトを除外させる方針を打ち出すと同時に、既存契約者へのフィルタリング使用の原則化を2009年1月以降に延期することとなった 。
これらの動きに符合して、国は、フィルタリングの強制化などの規制手段を取るのではなく、利用者の自律性を尊重し、このような民間の自主的取り組みとリテラシー向上を支援する立法措置や行政措置を講じている。
現在、新規・既存を問わず青少年契約者へのフィルタリング使用の原則化が完了し、更なる携帯電話フィルタリングの普及促進がなされると同時に、フィルタリング機能のカスタマイズ化などの画一的な現行モデルの改善策が引き続き進められている。その一方で、一部の地方自治体においては、青少年の携帯電話フィルタリングを実質的に義務化する動きもある。

排除方式
有害サイトへのアクセス制限は、主に未成年者の親権者が、未成年者のアクセスできるインターネット機器（パーソナルコンピュータや携帯電話）に対して行う。親権者はサイトのいくつかの情報を基準にアクセス制限を設けるが、全てのサイトを確認し、それぞれにアクセス制限を設けることは困難であるため、より簡便な方法として市販のフィルタリングソフトが利用される。また、一部検索エンジン（「キッズgoo」など）においてもフィルタリングサービスを実装している。フィルタリングソフト・フィルタリングサービスには以下のような方式でアクセス制限を設ける。実際には、ホワイトリスト方式以外の方式を組み合わせて利用されることが多い。

URLフィルタリング
見ていいサイト、悪いサイト等を、事前に決めておく方式。

レイティング方式
サイトに対して一定基準で格付け（レイティング）しておくことで、情報受信者がそのレイティング結果を利用して、受信者の価値判断でフィルタリングを行う方式。情報発信者が自ら格付けするセルフレイティングと、第三者が格付けする第三者レイティングがある。
インターネット上のコンテンツを対象にレイティングを行う機関としてインターネットコンテンツ審査監視機構（I-ROI）がある。

ブラックリスト方式
有害なウェブサイトのリスト（ブラックリスト）を作り、これらの情報を見せないようにする方式。ただし、別のアドレスに移転したり、海外サーバーを利用したりすることで、アクセス遮断を免れる可能性がある。
携帯電話フィルタリングにおいては、フィルタリングリスト提供会社が分類したカテゴリーに対して、携帯電話事業者がアクセス制限カテゴリーを指定し、当該カテゴリーに当てはまるサイトが自動的にアクセス遮断される仕組みとなっている。ただし、例外として、第三者機関が認定したサイトはアクセスを許可することとしている。
なお、2009年4月25日に発表された総務省から携帯電話事業者への要請では、親権者から申告又は記載がない場合に設定される原則ルールとして、ブラックリスト方式（特定分類アクセス制限方式）とすべきであるとしており、携帯電話事業者も対応する措置を実施済である。

ホワイトリスト方式
未成年者にとって安全で有益と思われるサイトのリスト（ホワイトリスト）を作り、これに該当しないサイトを見せないようにする方式。携帯電話においては、携帯電話事業者各社が認めた公式サイトであり、かつ限定したカテゴリーに属するサイトのみアクセスできる方式をホワイトリスト方式としている。したがって、非公式サイトはホワイトリストからは排除されている。
なお、総務省の「インターネット上の違法・有害情報への対応に関する検討会」中間とりまとめでは「13歳未満の小学生が利用する携帯電話のフィルタリングサービスとして推奨することは可能だが、18歳未満の青少年一般に推奨するには不適当であろう。」と結論付けており、その性格を明らかにするため「携帯事業者提供リスト方式」と呼ぶことがふさわしいとしている。

動的コンテンツフィルタリング
接続時の内容から動的に判断し、フィルタリングする。キーワード方式、フレーズ方式、全文検索方式などとも呼ばれる。最も単純には、未成年者にとって、有害と思われるキーワードやフレーズを指定し、これらのキーワードやフレーズを含むサイトを見せないようにするものである。

アクセス制限対象
フィルタリングリスト提供会社がサイト情報の収集をし、各サイトをカテゴリーごとに分類している。PC向けのソフトウェアでは各会社が制限対象となるカテゴリーあるいは個別のサイトを選定している。

携帯電話フィルタリングでのアクセス制限
携帯電話向けのフィルタリングサービスの内、ブラックリスト方式のサービスでは、携帯電話事業者各社が以下のカテゴリーで分類されているサイトをアクセス制限カテゴリー（ブラックリスト）として指定し、青少年名義の携帯電話への閲覧制限を行っている。 

不法（違法または違法と思われる行為、違法と思われる薬物、不適切な薬物利用）
主張（軍事・テロ・過激派、武器・兵器、告発・中傷、自殺・家出、主張一般）
アダルト（性行為、ヌード画像、性風俗、アダルト検索・リンク集）
セキュリティ（クラッキング、不正コード配布、公開プロキシ）
出会い（出会い・異性紹介、結婚紹介）
ギャンブル（ギャンブル一般） ※スポーツくじ、宝くじは対象外。
コミュニケーション（ウェブチャット、掲示板、IT掲示板）
グロテスク（グロテスク）
成人嗜好（娯楽誌、喫煙、飲酒、アルコール製品、水着・下着・フェチ画像、文章による性的表現、コスプレ）
オカルト（オカルト）

公共空間、学校、職場等でのアクセス制限
図書館、市役所など公共の施設に設置し不特定多数に利用されるパソコンや、小中高等学校の児童・生徒用パソコン、企業・官公庁の社員・職員用パソコンでは、フィルタリングによるアクセス制限を必須としており、アクセス制限カテゴリーは各組織において選定されるため、その運用実態は様々である。なお、各学校やプロバイダごとにアクセス制限対象を選別するのではなく、地方自治体による有害情報選別組織に権限を委ねているケースもある（後述）。

携帯電話フィルタリングの問題点
フィルタリングはあくまで民間企業の業務としてなされるものだが、携帯電話におけるフィルタリングは、各端末ごとにソフトウェアを組み込むことが困難である上、携帯電話市場が少数の企業により寡占されることから、民間企業の自主的な判断といえども、その影響が膨大な利用者全体に及ぶことになる。したがって、携帯電話のフィルタリングにおける公正性、透明性や実効性について、総務省が開催した「インターネット上の違法・有害情報への対応に関する検討会」等で、多くの問題点が指摘されている。

制度全体の問題点
携帯電話のフィルタリングにおいては、幅広い年齢層と様々な価値観、多様なニーズと利用形態があるにも関わらず、ホワイトリスト方式、ブラックリスト方式の2種類の選択肢だけしか存在しない。特に高校生等にとっては過度なアクセス制限になる。
携帯電話のフィルタリングにおいては、有害でないサイトも含めてフィルタリング対象が広範になりすぎている。
インターネットへの接続手段として既に青少年の日常生活には不可欠のものとなっており、利便性が損なわれる恐れがある。
携帯電話事業者が、どのようなサイトをアクセス可能とするのか決定プロセスが不透明である。
サイトの分類は営利企業であるフィルタリングリスト提供会社が行っているため、分類の基準や運用状況は企業独自のノウハウに属し、公表されていない。
利用者は、フィルタリングの可否を個別のサイトごとに選択できないため、コンテンツ事業者による主体的な努力を、直接利用者の意思に反映させることができない。
アクセス制限すべきカテゴリーにあるという理由で、青少年保護に配慮したサイトを全てを一律にフィルタリングの対象とすることは、青少年がかえってリスクの高い利用環境を選択することにつながりかねない。
海外サイトの場合は、EMAの認定を受けられないわけではないが、手続きの頻雑さから現時点で皆無であり、弊害として情報鎖国になる可能性がある（例：FacebookやtwitterやFC2など）。
過剰なフィルタリング設定は自殺への追い込みやスマートフォン等の使用意義をなくしてしまう場合がある。

ブラックリスト方式の問題点
ブラックリスト方式において、特定のカテゴリに分類されたサイトは有害でないサイトでもフィルタリングの対象となってしまう。。
ブラックリストの基準となる、アクセス制限対象のカテゴリーとするかどうかは携帯電話事業者が独自に判断している。
ブラックリスト方式においては、アダルトイラストを扱う個人のホームページなどのようにアダルトサイト(有害サイト)として認識されないサイトなどのケースもあって、親の目を盗んでアダルト目的でインターネットを利用する子供には有効性が働かない場合もある。

ホワイトリスト方式の問題点
後述のホワイトリスト方式においては携帯電話事業者により公式サイトとして認められたサイトである必要があり、公的機関を含む大多数の有害でないサイトが排除されてしまうこととなる。
ホワイトリストの基準となる、公式サイトに当たるかどうか最終的な決定は携帯電話事業者の裁量に委ねられており、その恣意性が指摘されている。

その他
VPNを使用すると、あらゆる通信を秘匿化できるためフィルタリングが機能しなくなる。そのため、アプリケーションのインストール制限やOS標準のVPN(iCloud プライベートリレーなど)の設定次第では回避が可能なためペアレンタルコントロールを適切に設定する必要がある。

携帯電話フィルタリングへの調査
保護者の意識
2009年3月18日、東京都青少年・治安対策本部は保護者を対象にした調査結果を発表。フィルタリングサービスへの加入が進んでいないと思う理由として、インターネット上の有害情報やフィルタリングについて、よくわからない保護者が多いからとの回答が45.0%、フィルタリングの仕組みが十分でなく、きめ細かい設定がまだできないからとの回答が36.0%であった。

認知率・普及率
2008年1月26日、内閣府は「インターネット上の安全確保に関する世論調査」を発表し、フィルタリングの認知は国民の6割に満たないと発表した。
2008年11月10日、2008年ユーキャン新語・流行語大賞の候補語に「フィルタリング」が選ばれた。
2009年4月15日、電気通信事業者協会は、フィルタリングサービス利用者数が2009年3月末時点で約573万人となり、3ヶ月間で約78万人増加したと発表した。
2019年11月25日、有識者会議で、日本の携帯大手3社は、18歳未満のフィルタリングサービスの加入率を初めて明らかにした。2019年10月にNTTドコモが64パーセント、KDDIが58パーセント、ソフトバンクが50パーセント、平均59パーセントだった。

国による取り組み
法的推進への動き
フィルタリングに対する個別の規制措置が検討される以前においては、「青少年有害社会環境対策基本法案」等において包括的に青少年環境整備を規律する法律案が検討されていた。具体的には、青少年有害社会環境対策センターを通じて、行政機関が有害情報掲載事業者に対する行政指導を行い、受諾しない場合に事業者名の公表を行う内容であった。
しかし、「青少年有害社会環境対策基本法案」に対しては、『「青少年有害環境のもたらす弊害が深刻化し、かつ増大している」というが、具体的にどのような現象を指すのか。また、少年犯罪の増加や凶悪化・それらと外的環境との明確な因果関係は、科学的・統計学的に証明されていない（少年犯罪そのものは昭和30年代がピークで件数は統計上はむしろ減少している）。』などの反対意見が多かったため、「青少年有害社会環境対策基本法案」は成立していない。
2007年12月10日、総務省は、携帯電話・PHS事業者などに対して、フィルタリングの導入促進のため、新規契約時における青少年のフィルタリング使用の原則化と不使用についての親権者の意思確認実施、及び既存契約者に対する意思確認の実施を促す総務大臣要請を発表した。
2008年4月17日、教育再生懇談会において、有害情報対策をめぐる状況について討議され、内閣総理大臣福田康夫（当時）は「携帯のフィルタリングの普及という議論の前に、携帯を持つべきかどうかということを議論していただいた方が私はいいと思う。」という見解を示した。
2008年4月25日、総務省は、「携帯電話・PHSのフィルタリングサービスの改善等に関する携帯電話事業者等への要請」を行った。その内容は、フィルタリングサービスの導入促進として、第三者機関により認定されたサイトや推奨されたアクセス制限すべきカテゴリーが反映されるよう協議し、対応することや、その周知と早期実施、親権者からの申告がない原則ルールとしてブラックリスト方式（特定分類アクセス制限方式）を適用すべきであること、親権者の意思確認を確実に実施すること、及び利用者の選択肢を増やす施策として、利用者において個別にサイトやカテゴリーへのアクセスを許可設定ができるサービス等の提供を検討し、早期対応、周知を図ることであった。
2008年6月11日、参議院本会議で「青少年が安全に安心してインターネットを利用できる環境の整備等に関する法律」（青少年インターネット環境整備法）が可決成立した。同法は、携帯電話事業者に対しては、保護者が不使用を申し出ない限り、フィルタリングの提供義務を課し（17条）、プロバイダに対しては、利用者の求めに対するフィルタリングの提供義務を課すこと（18条）や、フィルタリングソフトウェアの開発事業者やサービス提供事業者に対して、青少年の発達段階や利用者の選択に応じ、きめ細かく設定できるようにすること、閲覧の制限が行われることをできるだけ少なくすることに配慮する努力義務を課すこと（20条1項）を定め、フィルタリング推進業務者に対する任意での登録制度（24条）も盛り込まれた。

政府省庁による普及啓発活動
2007年2月16日、総務省と警察庁、文部科学省は合同で、都道府県、教育委員会及び都道府県警察などに対して、携帯電話におけるフィルタリング（有害サイトアクセス制限）の普及促進について、啓発活動に取り組むように依頼した。
2008年6月11日、「青少年が安全に安心してインターネットを利用できる環境の整備等に関する法律（青少年インターネット環境整備法）が可決成立し、フィルタリングの普及について国や自治体が必要な施策を講じること（14条）や啓発活動を行うこと（15条）が定められた。
2009年1月16日、総務省は、青少年インターネット環境整備法の趣旨に基づき、「安心ネットづくり」促進プログラムを定めた。　同プログラムでは、利用者側でフィルタリング対象のカスタマイズができる機能や、年齢層に応じたフィルタリングなど、フィルタリングサービスを多様化する環境整備の推進が盛り込まれている。

地方自治体による取り組み
フィルタリングへの直接的関与
新潟県は、県内の学校やプロバイダーでの有害情報の選別を行うため「新潟県スクールネット防犯連絡協議会」を設けている。 同協議会は、新潟県警に事務局を設置し、県の警察、教育、福祉等の各部署とプロバイダ団体、一部の民間有識者が会員となり、インターネット上の有害情報を登録するシステムを運用しており、このシステムを通じて県内の学校やプロバイダー加入者のインターネットアクセスを制御している。有害情報の登録員は警察や学校等が選任した者とされ、事後に有害情報審査員が登録維持か解除かの審査を行うものとされている。 しかし同協議会会則には、行政機関との情報遮断等の第三者性や公正性を担保する機関設計はもちろん、有害情報審査委員や関連機関の存在、審査基準自体も規定されていない。

条例による推進への動き
東京都青少年の健全な育成に関する条例（同18条の7）(2005年改正)や、大阪府青少年健全育成条例（同26条）など、都道府県単位で施行されるいわゆる青少年保護育成条例においては、インターネット事業者が利用者にフィルタリングソフトウェアの利用の提供や、保護者がそれを用いることが、努力義務の形で規定されている場合がある。
鳥取県青少年健全育成条例（同12条の2の3、2008年4月1日改正施行）や、広島市青少年と電子メディアとの健全な関係づくりに関する条例（同10条の3、2008年7月1日施行）では、それに加え、インターネットカフェや公共施設が利用者（ただし、利用者の年齢を確認できる場合は18歳未満の者に限る）にフィルタリングソフトウェアの利用の提供を行うことが、法的義務の形で規定されており、違反した場合は罰則（鳥取県。改善命令に従わなかった場合は50万円 の罰金、同26条の4）および事業者名の公表（広島市。同13条）がある。
2009年7月1日に全面施行される兵庫県青少年愛護条例では、青少年が携帯電話利用契約を締結するときに、その保護者がフィルタリングの不使用を申し出ることが可能な類型として、青少年が就労しており、業務に著しい支障を生ずることその他の規則で定める正当な理由があるとき（同24条の41項）に限定しており、同施行規則も、障害や疾病下にある青少年が日常生活に著しい支障を生ずる場合等（同施行規則12条）に限定しているため、事実上保護者による意思確認過程を無効化し、フィルタリング利用の義務化が図られている。

接続業者による取り組み
携帯電話事業者3社（NTTドコモ、KDDI、ソフトバンクモバイル）は、「有害サイトアクセス制限サービス」（フィルタリングサービス）を、2003年より順次、無料で提供している。
KDDIは、2007年2月13日から、未成年者がau電話の契約にともない、EZwebサービスを申込む場合は、「EZ安心アクセスサービス」の申込に関する親権者の意思確認を必須化した。
NTTドコモは、2006年11月20日から有害サイトアクセス制限サービス（フィルタリングサービス）を推奨強化し、未成年者が契約申込み時に提出する親権者同意書などを改善し、「有害サイトアクセス制限サービス」（フィルタリングサービス）の利用の有無について、親権者の意思確認を確実に行うこととした。また親権者の意思が確認できない場合には、未成年者からのインターネットサービスの申込みを受け付けない運用を実施した。また2007年3月1日からは、契約者が未成年の場合に限らず、全ての新規申込み時にアクセス制限サービスの利用意向確認を実施した。これにより、契約者名義が親権者で利用者が未成年という場合においても、アクセス制限サービスの利用意向確認を必ず実施されることとなった。
2007年10月からはウィルコムも「有害サイトアクセス制限サービス」（フィルタリングサービス）を開始しており、全国を網羅している大手キャリア4社全てがフィルタリングサービスを提供したことになる。
2009年8月31日、ソフトバンクモバイルが独自のフィルタリング方式として高校生の利用を想定した「ウェブ利用制限（弱）」を提供開始。ネットスター社が提供する「子どもの利用への配慮レベル1〜3」に分類されるサイトがアクセス可能となり、EMA認定を受けていないYahoo!ブログ等の閲覧が可能となった。

フィルタリングの効果
福井県警によると、2019年度以降に福井県内で起きたSNSを介した児童の性被害はすべて被害者児童がフィルタリング機能で有害なサイトの閲覧規制がされていない状態だった。県警は被害を未然に防ぐためにもフィルタリング機能を使用することを推奨している。

脚注
関連項目
情報通信法案 - 青少年が安全に安心してインターネットを利用できる環境の整備等に関する法律
強制アクセス制御
通信の秘密
有害情報 - 出会い系サイト - ソーシャル・ネットワーキング・サービス
パブリック・アクセス
リテラシー - 情報リテラシー - メディア・リテラシー
e-ネットキャラバン
Platform for Internet Content Selection (PICS)
モバイルコンテンツ審査・運用監視機構（EMA）
インターネットコンテンツ審査監視機構（I-ROI）
ネット風評監視サービス
インターネットコンテンツセーフティ協会
ネット社会健全化推進議員連盟
ネット社会の健全な発展に向けた連絡協議会
サイバーセキュリティ財団
情報法制研究所(JILIS)
セーファーインターネット協会
ソーシャルメディア利用環境整備機構
コンテンツフィルタリング
広告フィルタリング
i-フィルター（デジタルアーツ）
レイティング - アクセス禁止 - ペアレンタル・コントロール
キッズgoo
Yahoo!きっず
キッズケータイ
ジュニアケータイ
コドモバイル
ブロッキング
アダルトサイト

外部リンク
フィルタリング（有害サイトアクセス制限サービス）をご存知ですか？ - 総務省
フィルタリング情報ページ - インターネット協会
フィルタリング、知っていますか？ - インターネット協会
フィルタリングサービスを利用しましょう! - 安心ネットづくり促進協議会